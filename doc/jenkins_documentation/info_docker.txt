Теория о Докер файле 
image в докере это некий образ собраный из докер файла представляет из себя выполненые и запакованые в формат докера команды и ключевые слова
image обычно хроняться в централизованом хранилище, можно запустить неограниченное количество докеров из image на текщей машине огрничениме бут являться только ресурсы

Dockerfile файл
распространеные ключевые слова пишуться большими буквами, после чего идет параметр для этого ключевого слова

читаем с низу в верх

 \
/|\	Cлой 6: ENTRYPOINT (пишется команда при старте контейнера)
 |	Cлой 5: ADD (добавляем файлы приложения )

 \	Зависимости
/|\	Cлой 4:RUN (устанвока модули и библиотеки для приложения )
 |	Cлой 3:RUN (устанвока пакетов оs)

 \       Операциоонная система 
/|\	Cлой 2: RUN  (тут используются команды для настройки систем, дч установки дополнительних модулей и библеотек(обычно большие bash скрипты))
 |  	Cлой 1: FROM  debian:jessie (на этом этапе качаться базовый имедж, после на его основе внути него будет выполнять уже все отстальне команды указаныне в докер файле)
 
пример докер файла 
FROM python:3.6
RUN ln -snf /usr/share/zoneinfo/Europe/Moscow /etc/localtime && echo Europe/Moscow > /etc/timezone

RUN apt-get update -y && apt-get install -y curl
RUN pip install django

ADD . /app (.(откуда, текущая дериктория докер файла) /app(куда внути image будем добавлять файл))
ENTRYPOINT python /app/manage.py runserver 0.0.0.0:8000 --noreload (команда которая запускает нашь скрипт внутри контейнера)
открываем 8000 порт  0.0.0.0:8000 , иногда зыбают указать (не 127.0.0.1(будет слушать локолхость внути контейнера) нужно в докере указать 0.0.0.0(будет доступ))

после того как отредактировали Dockerfile необходимо собрать докер images
docker build . -t test:latest (.(место где находиться докер файл) -t(имя для докер файла ))

docker run -d -p 8000:8000 test
запускаю докер контейнер пробрасываю порты 8000 локалные на 8000 порты в докере 
curl 127.0.0.1:8000
увидим приветсвенное сообщение от приложения 

каждая деректива отдельный слой, все слои имеют рид онли формат, после выполнения уже не удасться записать в предыдущий слой 

	Cлой 6: ENTRYPOINT 
	Cлой 5: ADD expose 80 
	Cлой 4:RUN 
	Cлой 3:RUN
	Cлой 2: RUN
  	Cлой 1: FROM 
  	
OverlayFS - это файловая система, которая позволяет объединять несколько файловых систем в одну, создавая таким образом виртуальную файловую систему.
Она используется в Linux для создания контейнеров и виртуальных машин.
OverlayFS работает путем монтирования двух файловых систем в одну.
Она создает верхнюю файловую систему, которая содержит изменения, внесенные в файлы во время выполнения контейнера, и нижнюю файловую систему, которая содержит исходные файлы.
Все изменения, внесенные в файлы во время выполнения контейнера, сохраняются в верхней файловой системе, а исходные файлы остаются неизменными в нижней файловой системе.
OverlayFS позволяет создавать несколько контейнеров, используя одну и ту же базовую файловую систему, что позволяет экономить место на диске.
Она также обеспечивает быстрый доступ к файлам и позволяет создавать контейнеры с различными версиями приложений и библиотек.
OverlayFS является одним из наиболее популярных механизмов для создания контейнеров в Linux и используется в таких инструментах, как Docker и Kubernetes

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
хорошие практики (уменьшение размера докер images )
1. .dockerignore (в этом файле указваются какие файлы при запуске контейнера из текущей деректории не выкачивать в сам докер images) например при выполнение add
СОЗДАЕМ файл .dockerignore и прсото перечилляем те папки и файлы которые не нужно копировать 
2. удаляем кеши (пердустановленых компанент) из /var/lib/apt/lists/*
3. обязательно делаем установку и удаление в одном шаге!!!
RUN set -ex && \                         
    apt-get update && \
    apt-get install -y nginx && \
    rm -rf /var/lib/apt/lists/* 
4. Порядок выполнения шагов (код нужно выполнять уже после устанвоки компонет и приложений, т.к. они храняться в кеше)
5. логи в stdout/stderr (настраиваем логи в stdout/stderr )
    RUN set -ex && \
    ln -sf /dev/stdout /var/log/nginx/access.log &&\
    ls -sf /dev/stderr /var/log/nginx/error.log
5.1 что бы посмотреть логи в докер кантейнере нужно выполнить 
   docker logs (имя докер контейнера)
   покаджет последние 10 строк лога докер имеджа
   docker logs -f --tail 10 container_name

6. различие между ADD COPY (COPY-просто копирует содержимое контейнре) (ADD-разорхевирует все содержимое), елси не знаем для чего нам нужено ADD всегда копируем через COPY
6.1 ENTRYPOINT CMD (CMD делаавет все тоже самое что и ENTRYPOIN, при запуске docker run считает данные из ENTRYPOIN(если там узаказано что стартуем службу, она старнет) если мы пропишим в dokerfile CMD то у нас есть вариант по запуску контейне просто в консоли баш без выполнения скрипта   )
    


собоираем images из debian:jessie
FROM debian:jessie   

запускаем apt-get update после этого устанавливаем nginx
RUN apt-get update && \
    apt-get install -y nginx

добавляем в дерикрторию /etc/nginx/ докера, все что находиться в текущей дериктории 
ADD . /etc/nginx/

параметр EXPOSE 80 обозначет что контейнер по умолчанию будет открывать 80 порт. 
EXPOSE 80
ENTRYPOINT nginx -g 'daemon off;'
ENTRYPOINT запускает nginx (опция 'daemon off;' запускает nginx в форграунде, )
!!!!!!!!!!!!!стало!!!!!!!!!!!!!

FROM debian:jessie   

RUN apt-get update && \
    apt-get install -y nginx
RUN rm -rf /var/lib/apt/lists/* (так отработает не корректно, из-за того что каждая деректива отдельный слой, все слои имеют рид онли формат, после выполнения уже не удасться записать в предыдущий слой )

ADD . /etc/nginx/

EXPOSE 80
ENTRYPOINT nginx -g 'daemon off;'

!!!!!!!!!!!!!стало!!!!!!!!!!!!!

FROM debian:jessie   

RUN set -ex && \                          (отбражает в консоли логи всех выполняемых команд )
    apt-get update && \
    apt-get install -y nginx && \
    rm -rf /var/lib/apt/lists/* 
RUN set -ex && \
    ln -sf /dev/stdout /var/log/nginx/access.log &&\
    ls -sf /dev/stderr /var/log/nginx/error.log

COPY . /etc/nginx/

EXPOSE 80
ENTRYPOINT nginx -g 'daemon off;'




Background- Это значит, что сервис работает как фоновая задача не требующая взаимодействия с пользователем.
Foreground- Это сервис, о котором пользователь осведомлен. Это достигается с помощью отображения нотификации в статус-баре.
Пример foreground сервиса – отображение нотификации при проигрывании музыки в приложении-плеере

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
				 шпаргалка по соновным действиям с докером
https://habr.com/ru/companies/flant/articles/336654/
	I.  Build 
Сборка образа из Dockerfile в текущей директории
docker build -t image_name:tag .

Вот как выполнить docker build из файла с нестандартным именем (например, CustomDockerfile):
docker build -f CustomDockerfile -t your_image_name .


Изменение имени образа или тэга
docker tag old_image_name new_image_name

Сохранение образа в файл images.tar
docker save image_name -o image.tar

Загрузка образа из файла 
docker load -i image.tar



	II. Run
Что бы создать и запустить контейнер 
docker run image_name:tag

Полезные параметры для команды run 
-d - Запуск контейнера в фоне
-rm - Удаление контейнера после остановки

-p - проксирование локального порта в порт контейнера
-e - переменные окржения, передаваемые приложению
-v - Подключение вольюмов в контейнер
-ti - Инетерактивный режим (для запуска шела)



	III. List
Сиско всех запущеных контейнеров
docker ps 

Список всех контейнеров
docker ps -a

Все образы на сервере
docker images



	IV. Clean UP
Удаление всех имеджей неиспользуемых контейнеров 
docker image prune -a 

Удаление всех остановленых контейнеров
docker container prune -f

Остановка запущеного контенйнера
docker stop container_name
docker kill container_names



	V. Images
Скачать имадж
docker pull image_name:tag

Загрузка имеджа в registry
docker push image_name:tag

как сделать пуш images на 55.245 в local registry
для начала нужно сделать tag на 55.242
sudo docker tag ntjenkins:setup_LDAP 192.168.55.242:443/ntjenkins:setup_LDAP
после сделать push в local registry на 55.242
sudo docker push 192.168.55.242:443/ntjenkins:setup_LDAP
далее качаем образ на 55.245 из registry 55.242
sudo docker pull 192.168.55.242:443/ntjenkins:setup_LDAP
делаем tag на 55.245
sudo docker tag 192.168.55.242:443/ntjenkins:setup_LDAP 192.168.55.245:5000/ntjenkins:setup_LDAP
и после этого уже добавляем docker imaages в regestry на 55.245
sudo docker push 192.168.55.245:5000/ntjenkins:setup_LDAP

что бы проверить добаленые images, достаточно сдеалть ls на следующие каталоги:

показывает какиме есть имеджес
ls /var/lib/registry/docker/registry/v2/repositories

показывает какие есть tags имаджей 
ls /var/lib/registry/docker/registry/v2/repositories/busybox/_manifests/tags/



Просмотр команды в Имадже
docker history image_name:tag --no-trunc
192.168.55.245:5000/ntjenkins:pipline_for_packages


	VI. One-liners
Удаление всех контейнеров 
docker rm -f $(docker ps -qa)
удаление контейнера и его тома
docker rm -v nginx

Удаление неименованных образов 
docker rmi $(docker images -q -f danling=true)

Просмотр файла в контейере
docker exec container_name cat /etc/config.conf

получение доступ через консоль в контейнере
sudo docker exec -it 636e66119c76 /bin/bash


показывает все тома докер конетнера 
docker volume ls
DRIVER    VOLUME NAME
local     jenkins-data
local     jenkins-docker-certs
local     vscode

Copy files from container to local path

 docker cp CONTAINER:/var/logs/ /tmp/app_logs

удалать тома докер конетенера
docker volume rm jenkins-data

покажет докер сети
docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
3c0705233be6   bridge    bridge    local
55cdc0bc4ebe   host      host      local
6c9e306c2e8a   jenkins   bridge    local
58ed3bc3ba80   none      null      loca
 
удалит докер сеть
docker network rm 3c0705233be6

покажет только то что можно в качетве аргументов docker это ключить -
$(docker network ls -q)

Обновление контейнера
docker update --cpu-shares 512 -m 300M infinite

Подключение к существующему контейнеру(показывает инфо) при 2. SIGINT (2) - Сигнал прерывания от клавиатуры (Ctrl+C).  выходит из контенера
docker attach c7c37560fd28
2024-05-15 12:37:54.787+0000 [id=40]	INFO	jenkins.InitReactorRunner$1#onAttained: Completed initialization
2024-05-15 12:37:54.809+0000 [id=24]	INFO	hudson.lifecycle.Lifecycle#onReady: Jenkins is fully up and running

2024-05-15 12:37:55.317+0000 [id=67]	INFO	h.m.DownloadService$Downloadable#load: Obtained the updated data file for hudson.tasks.Maven.MavenInstaller
2024-05-15 12:37:55.318+0000 [id=67]	INFO	hudson.util.Retrier#start: Performed the action check updates server successfully at the attempt #1

информация о конетнере
docker inspect c7c37560fd28

покажет какие порты используются 
 docker port 70c813ce045c
8080/tcp -> 0.0.0.0:8880
8080/tcp -> [::]:8880
50000/tcp -> 0.0.0.0:50000
50000/tcp -> [::]:50000


покажет выполняющиеся процессы
docker top 70c813ce045c
UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
g10                 68117               68097               0                   15:43               ?                   00:00:00            /usr/bin/tini -- /usr/local/bin/jenkins.sh
g10                 68161               68117               72                  15:43               ?                   00:00:54            java -Duser.home=/var/jenkins_home -Djenkins.model.Jenkins.slaveAgentPort=50000 -Dhudson.lifecycle=hudson.lifecycle.ExitLifecycle -jar /usr/share/jenkins/jenkins.war

Использование ресурсов
docker stats 70c813ce045c

CONTAINER ID   NAME        CPU %     MEM USAGE / LIMIT     MEM %     NET I/O           BLOCK I/O         PIDS
70c813ce045c   ntjenkins   0.61%     1.862GiB / 15.48GiB   12.03%    3.06MB / 87.3kB   1.09MB / 6.32MB   61



Перезагрузка

docker restart nginx


для полного переноса докер контейнера необзодимо сокпировать volume докер том

  --volume jenkins-data:/var/jenkins_home \
  
docker cp 8a9d5399c5d4:/var/jenkins_home ./
и распоковать его в туже дерикторию в новом контейнере
  --volume jenkins-data:/var/jenkins_home \
   -v /home/esermyagin/Desktop/123/script2/script/Jenkins/Docker_iso_whit_Jenkins/jenkins_home:/home/g10 \




=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
                                        Идеалогия докер
1.(стандартизация)Контейнер, это про стандартизированую поставку, открытие и использование помещенного в докер обьекта (стандартизация)
*Сборка
*Поставка
*Конфигурация 
2.Воспроизводимость 
Все узависимости и код который был заложен на тк в имедж докера можно перенести на другие пространства
3. Консистентность
уверенсоть что в продакшен запустили то что уже проверили 

пример 
=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
https://telegra.ph/O-rabote-kontejnerov-v-celom-04-18
                                        Docker engine
что из себя представляет сам контейнер 
					  Container
					/     |       \
				Namespace     |  	      CGroup
                                /      \	      |	              /     \
			     /  \    /  \      | 	   /  \   /  \
		         Pid  Net  Mnt User     |	         CPU  Mem I/O Net
		         		      |
		         		     CoW  		
2 ключиевые технолгие которые реализует собой контейнер это Namespace и CGroup
Namespace вшитая в ядро linux технология, механизм обеспечивающий изоляцию процессов друг от друга(Pid,Net,Mnt,User)
CGroup вшитая в ядро linux технология, механизм изолирующий вычислительные ресурсы процессов (CPU,Mem,I/O,Net)
CoW (Copy-on-Write)- при чтении области данных используется общая копия, в случае изменения данных - создается новая копия 

Namespace (NS) 
    * Pid NS
         -Процессы в Pid NS видят только процессы в том же NS
         -У каждого PID ns своя нумерация начинается с 1
	 -Когда завершается PID весь NS перестает существовать
    *Net NS(пространство имен в сети )
	 -Процессы в рамках своего net ns получают свое сетевое окружение
	    - Сетевые интерфейсы (в том числе lo)
	    - Таблицу маршрутизации
	    - Правила iptables
	    - Сокеты
	 - Veth 
	 - Общий lo для нескольких контейнеров
    *Mnt NS - при каждом запуске контейнера, он получает свою собственную файловую систему, если мы выйдем или удалим контейнер, данных которые записывал туда сарый контейнер не сохраниться 
    	- Процеесы может иметь свою root fs 
    	- /tmp
    	- /sys и /proc
    * User NS - (нужно следить за правами, при создании контейнера, елси создается под руутом то и у процеса будут права рута)
    	- Позволяет шарить GiD/UiD
    	   - Можно смапить UiD 0 (root) в нерутовый UiD в хостовом NS
    	   
CGroup 
    - Управляет ресурсами для процесса
    - Добавляет overhead 
    	- или нет (если н нашей системе захотим ограничить по памяти, unix дложны считать количество выдаваемой памяти)
    -определение CPU ограничений должно поддердиваться седствами приложения 
    
Copy-on-Write
	-image (CoW) 

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
					Storage drivers

  для ubuntu обычно использую AUFS
  
Storage driver в Docker - это механизм, который управляет хранением и управлением файлов в контейнерах Docker.
Storage driver определяет, как Docker хранит и управляет файлами в контейнерах Docker, включая файловую систему контейнера, образы Docker и тома данных.
Docker поддерживает несколько различных storage driver'ов, включая overlay2, aufs, devicemapper, btrfs и zfs.
Каждый storage driver имеет свои преимущества и недостатки, и выбор конкретного storage driver зависит от конкретных потребностей и требований.
Например, overlay2 является рекомендуемым storage driver'ом для большинства случаев использования Docker, так как он обеспечивает высокую производительность и надежность.
Однако, если вы используете Docker на старой версии ядра Linux, то вы можете использовать devicemapper в качестве storage driver'а.
В целом, storage driver в Docker является важным компонентом, который обеспечивает эффективное и надежное хранение и управление файлами в контейнерах Docker.  	   


Вы можете узнать, какой storage driver используется в Ubuntu, выполнив следующую команду в терминале:
sudo docker info | grep "Storage Driver"
Эта команда выводит информацию о Docker, включая используемый storage driver. Результат будет выглядеть примерно так:
Storage Driver: overlay2
В этом примере используется storage driver "overlay2".

для Ubuntu рекомендуется использовать Storage driver- AUFS 

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
https://habr.com/ru/companies/skillfactory/articles/547116/
Если внимательно посмотреть на полученные результаты, можно заметить, что они весьма похожи на те, что мы уже наблюдали после применения команды mount, не находите?

LowerDir: это каталог, в котором слои образа, доступные только для чтения, разделены двоеточиями.

MergedDir: объединённое представление всех слоев образа и контейнера.

UpperDir: слой для чтения и записи, на котором записываются изменения.

WorkDir: рабочий каталог, используемый Linux OverlayFS для подготовки объединённого представления.

docker inspect 192.168.55.245:5000/ubuntu2004_amd64:240307_Mellanox |jq .[0].GraphDriver
{
  "Data": {
    "LowerDir": "/var/lib/docker/overlay2/9c0dce41d545a950b363160c4ae93ced6a165a38cae524d1e0f6ed59fe496da4/diff:/var/lib/docker/overlay2/6fd55ae7afd10a66c8cb6d87d440eaa7407ade78b8e8685e4212c50ee1b16e73/diff:/var/lib/docker/overlay2/5c60011357a35bb950ac035cbe1e7ca802431bd257fd4af82cf9ffdf531621ce/diff:/var/lib/docker/overlay2/58c895ba67063eb056d4095f131dc12172bfab12d0b9ac6b2391c46671e7c195/diff:/var/lib/docker/overlay2/3d0da25d16a64b4999f2becbc5b7592acc157a88f4c8769e297ad7ad5ff18b66/diff:/var/lib/docker/overlay2/2bff7f554aa0cea51d0fc8df5d248a380b473372e3ea240fcc7d0441cf287687/diff:/var/lib/docker/overlay2/8610e8f23d8f4c7dbb9da286dbea38b865bcafd12f0d7d66e6955827f0af9eaf/diff:/var/lib/docker/overlay2/d1ac4540fd5160815625f554d2f40652a97d4c35f23629053c013bcaaa6caca8/diff:/var/lib/docker/overlay2/62a3eb8c04439c829b16d572ab2805924c16abe5543ba8bdfa89678a9948556e/diff:/var/lib/docker/overlay2/5ddaec0efb76b7945b65be4ba4095016958244e15daee3817d7e49ad03554d98/diff:/var/lib/docker/overlay2/f8a5141d89be37ad2908015ff72612bc0e5c9761fff0cd0f3f684371b8e8ce00/diff:/var/lib/docker/overlay2/8cffdd62da0526f7dc7493e052ec2ad934c5dc0a384e5d816838cc1cfd1f193c/diff:/var/lib/docker/overlay2/3f04441d7ce8b2284426cbc211f289681d290805b2e7a5ac0d01e760ccbb74ff/diff:/var/lib/docker/overlay2/6f11e608afe5ef634d8e46d6de1db6a6d03f793af3a064264d4e8fa79d9f49d6/diff:/var/lib/docker/overlay2/8d60d5096a28a135fe1ace513b2200ab0d46df8ac760c01df79a454b74bd26d8/diff:/var/lib/docker/overlay2/d7c4c07a294677c436cd320f76e971ed1dfb1646775afdd5c4125528473737d9/diff:/var/lib/docker/overlay2/33d57761ce4861400ce203cfd934407e0f8057b409d46aa9f04b71d6dc8f9c99/diff:/var/lib/docker/overlay2/57da55b378d9b21e0845e29fe81b37b4c549fc9fd4f4d9f5ccefb2807a7a6bfa/diff:/var/lib/docker/overlay2/7c2e96d661d310c1cd0fd747d3008938d3bb30747afe132d9e0f4f831cac5067/diff:/var/lib/docker/overlay2/d17db9bf0be393f259209dd68afd89f4804c37ff6e36518775fcb4d69bb8674e/diff:/var/lib/docker/overlay2/d10c9f97b5fefc05e08bfe2eac07d143511334cec55218794d2a8b95bea8c7f9/diff",
    "MergedDir": "/var/lib/docker/overlay2/43afc685c2312f9d08016fe71de619b144996668c373dde6d6493ea6c0819346/merged",
    "UpperDir": "/var/lib/docker/overlay2/43afc685c2312f9d08016fe71de619b144996668c373dde6d6493ea6c0819346/diff",
    "WorkDir": "/var/lib/docker/overlay2/43afc685c2312f9d08016fe71de619b144996668c373dde6d6493ea6c0819346/work"
  },
  "Name": "overlay2"
}
=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
http://192.168.55.245/redmine/projects/support/wiki/Настройка_тестового_стенда_и_включение_в_Jenkins_при_необходимости
ибо подключить полный список необходимых репо либо переключиться на наши зеркала следующей командой:
wget -qO - http://192.168.55.245/nt-repo/nt-repo-switch-to-mirror.sh -e use_proxy=yes | sudo -E bash;

Поставить на тестовый стенд docker и python3 и добавить в группу docker пользователя g10
wget -qO - http://192.168.55.245/nt-repo-dev/nt-repo-dev-init.sh -e use_proxy=yes | sudo -E bash; \
sudo apt-get update; \
sudo apt-get install -y python3 python3-pip qemu binfmt-support qemu-user-static docker.io libconfig++-dev apt-show-versions; \
sudo pip3 install --proxy http://192.168.55.253:3128 robotframework robotframework-sshlibrary pexpect; \
sudo usermod -aG docker g10; \
sudo systemctl status docker

Выкачать архив с мультиархитектурными образами
sudo mkdir -p /etc/systemd/system/docker.service.d; \
echo -en '[Service]\nEnvironment="HTTP_PROXY=http://192.168.55.253:3128/"\nEnvironment="HTTPS_PROXY=http://192.168.55.253:3128/"\n' | sudo tee /etc/systemd/system/docker.service.d/http-proxy.conf; \
sudo systemctl daemon-reload; \
sudo systemctl restart docker;

docker run --rm --privileged multiarch/qemu-user-static --reset -p yes --credential yes

sudo rm -rf /etc/systemd/system/docker.service.d; \
sudo systemctl daemon-reload; \
sudo systemctl restart docker;

Править /etc/fstab
grep 'errors=remount-ro,suid' /etc/fstab || sudo sed -i 's|errors=remount-ro|errors=remount-ro,suid|' /etc/fstab

Добавить сертификаты для работы докера
openssl s_client -showcerts -connect 192.168.55.242:443 < /dev/null | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > ca.crt; sudo mv ca.crt /usr/local/share/ca-certificates/;sudo update-ca-certificates;sudo systemctl restart docker.service;

Исправляет следующую ошибку:
Error response from daemon: Get https://192.168.55.242:443/v2/: x509: certificate signed by unknown authority

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
првоерить какие образы докера присутствуют 
docker images
sudo docker images
REPOSITORY                              TAG        IMAGE ID       CREATED         SIZE
192.168.55.242:443/metrics/ubuntu2204   1.1.10-4   d6236fde91cd   5 weeks ago     1.19GB
192.168.55.242:443/metrics/ubuntu1804   latest     b7e82467bd83   15 months ago   773MB

показывает что стартует
docker ps
sudo docker ps -a

CONTAINER ID   IMAGE                                   COMMAND                  CREATED        STATUS                  PORTS                                                                                                                                                                                                   NAMES
2c3f5aa5ede9   192.168.55.242:443/metrics/ubuntu1804   "/bin/bash -c 'sourc…"   6 months ago   Up Less than a second   0.0.0.0:2003->2003/tcp, :::2003->2003/tcp, 0.0.0.0:2023-2024->2023-2024/tcp, :::2023-2024->2023-2024/tcp, 127.0.0.1:8081->80/tcp, 0.0.0.0:29161->161/udp, :::29161->161/udp, 127.0.0.1:8082->3000/tcp   ntmetrics

Стопай сервис,
sudo systemctl restart docker
sudo systemctl status docker

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

запускаем докер 
docker run -it --rm --shm-size=10g --privileged --cap-add=ALL 192.168.55.242:443/18.04_amd64_git /bin/bash


так же есть скрипт запука run_docker_container.sh


=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
пробрасываем порт в докер 
docker run -d -p host_port:container_port your_image_name
docker run -d -p 8080:80 ngnix:1.13
-d обзначает, что запускаем контейнер в бекграунд режиме (т.е в фоне)
-p обозначает что локальный порт 8080 пробрасываем на 80 порт самого контейнера

проверка 
curl 127.0.0.1:8080 -i 

показывает информацию об ngnix


=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

при запуске docker контейнера и включение атрибута -v создает в контейнере общую папку путь до локальной дерикории/путь до сощдоваемой дериктории в докер контейнере 

docker run --privileged --rm -it --shm-size=10g --cap-add=ALL -v /home/esermyagin/Desktop/123/script/Jenkins:/home/g10/serm 

атрибут -w указывает с какой дериктории стартовать
-w /home/g10/serm 

указав -h при запуске скрипта 
./run_docker_container.sh -h


при указании атрибута --name можно назначить имя докеру 
--name=test_jen

=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
посмотреть логи запущеного контейнера 

sudo docker logs gifted_bouman

где gifted_bouman имя контейнера 
=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=


docker network create --subnet 172.17.1.0/24 --gateway=172.17.1.1 --ip-range 172.17.1.0/24 --driver=bridge --label=ntpipe_test ntpipe_test
docker run --rm -it -v /home/g10/asolomina/test_nt-pipe/tests/writer_reader_shm:/writer_reader_shm --name node1_nt-pipe --network ntpipe_test --ip=172.17.1.2 -w /writer_reader_shm ubuntu1804_nt-pipe_new
docker run --rm -it -v /home/g10/asolomina/test_nt-pipe/tests/writer_reader_shm:/writer_reader_shm --name node2_nt-pipe --network ntpipe_test --ip=172.17.1.3 -w /writer_reader_shm ubuntu1804_nt-pipe_new



=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
смена docker tag и имени 

docker tag <image_name> <new_image_name>:latest

udo docker tag ntjenkins0.2:lts-jdk11 ntjenkins:setup_MAIL



=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
 
 изменения в нем можно будет пулить в докер и комментировать
ну и переносить между машинами, ломать, пробовать и все такое 
 
Docker commit - это команда Docker, которая позволяет создавать новый образ Docker на основе измененного контейнера Docker. Команда Docker commit создает новый образ Docker, который содержит все изменения, внесенные в контейнер Docker после его запуска.

Когда вы запускаете контейнер Docker, вы можете вносить изменения в его файловую систему, устанавливать новые пакеты, настраивать приложения и т.д. Когда вы готовы сохранить эти изменения в новый образ Docker, вы можете использовать команду Docker commit.

Команда Docker commit принимает два аргумента: идентификатор контейнера Docker и имя нового образа Docker. Например, вы можете выполнить команду
 docker commit <CONTAINER_ID> my-new-image, 
 где <CONTAINER_ID> - это идентификатор контейнера Docker, а my-new-image - это имя нового образа Docker.
 
 sudo docker commit 636e66119c76 initial_setup_with_ru_localizationjenkins











Команда docker commit создает новый образ на основе состояния запущенного контейнера. Однако не все данные из контейнера сохраняются в новом образе. Несохраненные данные включают:

• Сгенерированные данные: Данные, созданные контейнером во время выполнения, такие как журналы, файлы кеша и временные файлы, не сохраняются в образе.
• Измененные файлы: Если в контейнере были изменены файлы, но эти изменения не были зафиксированы в базовом образе, они не будут сохранены в новом образе.
• Смонтированные тома: Данные, смонтированные в контейнер из томов вне контейнера, не сохраняются в образе.
• Переменные окружения: Переменные окружения, установленные в контейнере, не сохраняются в образе.
• Состояние сети: Состояние сети контейнера, такое как IP-адрес и порты, не сохраняется в образе.

Чтобы сохранить все данные из запущенного контейнера в новом образе, используйте следующие методы:

• Используйте флаг --changes: Флаг --changes включает в новый образ все изменения, внесенные в контейнер, в том числе измененные файлы и сгенерированные данные. Однако он не включает смонтированные тома и другие динамические данные.

• Сохраните данные в постоянном хранилище: Используйте команды docker cp или docker volume для копирования данных из контейнера в постоянное хранилище, такое как том или объект облачного хранилища. Затем смонтируйте постоянное хранилище в новый контейнер, созданный из образа.

• Используйте пользовательский скрипт: Создайте пользовательский скрипт, который будет выполняться при запуске нового контейнера, созданного из образа, и который будет восстанавливать необходимые данные из постоянного хранилища.

Примечание: Всегда рекомендуется проверять новый образ, чтобы убедиться, что в нем сохранены все необходимые данные.


приведи пример команды  docker commit c ключем --changes


**Пример команды `docker commit` с ключом `--changes`:**

```
docker commit --changes --author "Ваше имя" <идентификатор-контейнера> <имя-нового-образа>
```

где:

* `--changes`: Этот флаг сохраняет в новом образе все изменения, внесенные в контейнер, в том числе измененные файлы и сгенерированные данные.
* `--author`: Этот флаг задает автора нового образа. Замените `Ваше имя` своим именем или псевдонимом.
* `<идентификатор-контейнера>`: Замените это фактическим идентификатором или именем запущенного контейнера, из которого вы хотите создать образ.
* `<имя-нового-образа>`: Замените это желаемым именем нового образа.

**Например:**

Чтобы создать новый образ с именем `my-new-image` на основе запущенного контейнера с идентификатором `123456789abcdef`, сохранив все изменения, внесенные в контейнер:

```
docker commit --changes --author "Джон Доу" 123456789abcdef my-new-image
```

После выполнения этой команды будет создан новый образ с именем `my-new-image`, который включает все изменения, внесенные в контейнер `123456789abcdef`.

**Примечание:** Флаг `--changes` не сохраняет смонтированные тома и другие динамические данные в новом образе. Если вам необходимо сохранить эти данные, используйте методы, описанные в моем предыдущем ответе.












После выполнения команды Docker commit будет создан новый образ Docker, который содержит все изменения, внесенные в контейнер Docker после его запуска. Этот новый образ Docker можно использовать для запуска новых контейнеров Docker, которые будут содержать все изменения, внесенные в исходный контейнер Docker.

Важно отметить, что команда Docker commit не является рекомендуемым способом управления конфигурацией и версионирования приложений в Docker. Вместо этого рекомендуется использовать инструменты управления конфигурацией, такие как Ansible, Chef или Puppet, а также системы контроля версий, такие как Git, для управления конфигурацией и версионирования приложений в Docker.



Команда sudo docker commit используется для создания нового образа Docker на основе изменений, внесенных в существующий контейнер Docker. 

В данном случае, команда создает новый образ Docker на основе контейнера с идентификатором 636e66119c76, а затем называет его initial_setup_with_ru_localization и присваивает ему тег sha256:77b58603dc95d07b76b1bba7eb999c4b058f117cf2e6cb0334746882bfd5db91.

Чтобы использовать этот новый образ, вы можете запустить его с помощью команды docker run и указать его имя и тег:

docker run -it initial_setup_with_ru_localization:sha256:77b58603dc95d07b76b1bba7eb999c4b058f117cf2e6cb0334746882bfd5db91

Эта команда запустит новый контейнер на основе созданного образа и откроет интерактивную оболочку внутри контейнера.



=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

docker run --name ru_docker_jenkins --restart=on-failure --detach \
  --network jenkins_ru_localization --env DOCKER_HOST=tcp://docker:7777 \
  --volume jenkins-data:/var/jenkins_home \
  --volume jenkins-docker-certs:/certs/client:ro \
  --publish 9080:9080 --publish 59999:59999 initial_setup_with_ru_localization


опиши что тут происходит 
docker run --name myjenkins --restart=on-failure --detach \
  --network jenkins --env DOCKER_HOST=tcp://docker:2376 \
  --volume jenkins-data:/var/jenkins_home \
  --volume jenkins-docker-certs:/certs/client:ro \
  --publish 8080:8080 --publish 50000:50000 jenkins
Эта команда запускает контейнер Docker с образом Jenkins и настраивает его для работы в сети jenkins. Разберем каждую опцию по порядку:

- --name myjenkins - задает имя контейнера, в данном случае myjenkins.
- --restart=on-failure - определяет, как контейнер будет перезапускаться в случае сбоя. В данном случае, контейнер будет перезапущен только в случае ошибки.
- --detach - запускает контейнер в фоновом режиме.
- --network jenkins - подключает контейнер к сети jenkins.
- --env DOCKER_HOST=tcp://docker:2376 - устанавливает переменную окружения DOCKER_HOST в значение tcp://docker:2376. Это позволяет контейнеру обращаться к Docker-демону, работающему на хост-машине.
- --volume jenkins-data:/var/jenkins_home - монтирует том jenkins-data в директорию /var/jenkins_home внутри контейнера. Это позволяет сохранять данные Jenkins между запусками контейнера.
- --volume jenkins-docker-certs:/certs/client:ro - монтирует том jenkins-docker-certs в директорию /certs/client внутри контейнера в режиме "только для чтения" (ro). Это позволяет контейнеру использовать сертификаты клиента Docker для безопасного подключения к Docker-демону.
- --publish 8080:8080 - открывает порт 8080 в контейнере и привязывает его к порту 8080 на хост-машине. Это позволяет получить доступ к веб-интерфейсу Jenkins через браузер на хост-машине.
- --publish 50000:50000 - открывает порт 50000 в контейнере и привязывает его к порту 50000 на хост-машине. Это позволяет настраивать удаленные агенты Jenkins для выполнения сборок на хост-машине.
Имя Docker-образа указывается в конце команды docker run, после параметра --publish. В данном случае, имя образа - jenkins. 
Команда docker run используется для запуска Docker-контейнера на основе Docker-образа. Параметр --name задает имя контейнера, --restart определяет, как контейнер будет перезапускаться в случае сбоя, --detach запускает контейнер в фоновом режиме.
Параметр --network указывает, какую сеть использовать для контейнера. --env задает переменную окружения, которая будет доступна внутри контейнера. --volume монтирует тома в контейнере, --publish открывает порты на хосте и направляет их на контейнер.
Таким образом, команда запускает контейнер на основе образа jenkins, называет его myjenkins, задает параметры перезапуска и сети, монтирует тома и открывает порты.


В итоге, эта команда запускает контейнер Jenkins с настройками, необходимыми для его работы в сети jenkins и обеспечивает доступ к веб-интерфейсу Jenkins через браузер на хост-машине.
что делает docker network create jenkins?
Команда docker network create jenkins создает новую сеть Docker с именем "jenkins". Это позволяет контейнерам, запущенным в этой сети, общаться друг с другом по именам контейнеров вместо IP-адресов. Это может быть полезно, когда необходимо запустить несколько контейнеров, которые должны взаимодействовать друг с другом в рамках одной сети.


=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

sudo docker run --privileged --rm -it --shm-size=10g --cap-add=ALL -e gatz=$gatz -v /home/esermyagin/Desktop/123/script/Jenkins:/home/g10/serm  -w /home/g10/serm 192.168.55.242:443/20.04_amd64_git ./checking_the_installing_components


В представленном коде происходит запуск Docker-контейнера с использованием команды docker run. Давайте разберемся, что здесь происходит:

1. sudo - это команда, используемая для выполнения следующей команды с правами суперпользователя.

2. docker run - это команда Docker CLI для создания и запуска Docker контейнера.

3. --privileged - это опция, которая предоставляет контейнеру полные привилегии, позволяющие выполнять привилегированные операции на хостовой машине.

4. --rm - это опция, которая указывает Docker удалить контейнер после его остановки.

5. -it - это опция, которая создает интерактивный терминал и подключает его к контейнеру, позволяя взаимодействовать с ним из командной строки.

6. --shm-size=10g - это опция, которая устанавливает размер разделяемой памяти (shared memory) для контейнера. В данном случае, размер установлен на 10 гигабайт.

7. --cap-add=ALL - это опция, которая добавляет все возможные привилегии (capabilities) в контейнер, позволяя выполнять привилегированные операции.

8. -e gatz=$gatz - это опция, которая задает environment variable (переменную окружения) gatz в контейнере и присваивает ей значение из переменной $gatz.

9. -v /home/esermyagin/Desktop/123/script/Jenkins:/home/g10/serm - это опция, которая монтирует локальную директорию /home/esermyagin/Desktop/123/script/Jenkins на путь /home/g10/serm внутри контейнера. Это позволяет доступиться к файлам и директориям извне контейнера.

10. -w /home/g10/serm - это опция, которая устанавливает рабочий каталог (working directory) внутри контейнера в /home/g10/serm. Это означает, что все команды будут выполняться в этом каталоге.

11. 192.168.55.242:443/20.04_amd64_git - это имя Docker образа, который будет использован для создания контейнера.

12. ./checking_the_installing_components - это команда, которая будет выполнена внутри контейнера.

Таким образом, весь этот код используется для создания и запуска Docker контейнера с определенными настройками и параметрами, включая монтирование директории, задание переменной окружения и выполнение команды внутри контейнера.


=-=-=-=-=-=-=-=-=--=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

ошибка в клонирвоание докер зеркал 
Downloading https://download.docker.com/linux/ubuntu/dists/bionic/Release...
Success downloading https://download.docker.com/linux/ubuntu/dists/bionic/Release
Downloading https://download.docker.com/linux/ubuntu/dists/bionic/Release.gpg...
Success downloading https://download.docker.com/linux/ubuntu/dists/bionic/Release.gpg
gpgv: Signature made Вт 13 июн 2023 10:55:10 MSK
gpgv:                using RSA key 7EA0A9C3F273FCD8
gpgv: [don't know]: invalid packet (ctb=2d)
gpgv: keydb_search failed: Invalid packet
gpgv: Can't check signature: No public key
ERROR: unable to fetch mirror: verification of detached signature failed: exit status 2
e.sermyagin@git:~/ntrepo/aptly$ aptly -config=./etc/aptly-mirror.conf mirror create  docker-1804-stable https:/



Эта ошибка связана с тем, что вам не хватает открытого ключа (public key) в вашем доверенном кольце ключей для проверки подписи пакета. Для исправления этой проблемы вам необходимо импортировать отсутствующий открытый ключ в ваше доверенное кольцо ключей.

Вот как вы можете импортировать открытый ключ с помощью команды gpg, как предложено в сообщении об ошибке:

1. Используя ключевую команду, импортируйте отсутствующий ключ с сервера ключей Ubuntu:
   ```bash
   gpg --no-default-keyring --keyring trustedkeys.gpg --keyserver keyserver.ubuntu.com --recv-keys 7EA0A9C3F273FCD8
   ```

2. Если ключ сохранен в файле Release.key в корне репозитория, вы можете также импортировать его напрямую из файла:
   ```bash
   wget -O - https://some.repo/repository/Release.key | gpg --no-default-keyring --keyring trustedkeys.gpg --import
   ```

После того как вы импортируете отсутствующий открытый ключ, вы повторно попробуйте выполнить операцию, которая вызвала ошибку, и проверьте, что проблема с проверкой подписи решена.













RUN groupadd --gid 1000 g10 && useradd --home-dir /home/g10 --create-home --uid 1000 --gid 1000 --shell /bin/bash --skel /dev/null g10


Эта запись в Dockerfile используется для создания новой группы и пользователя в образе Docker. Давайте разберём каждую часть этой инструкции:

1. RUN - это ключевое слово, которое указывает Docker на выполнение команды во время построения образа.
   
2. groupadd - это команда для создания новой группы. В данном случае, --gid 1000 указывает идентификатор группы, который равен 1000, и g10 является названием этой группы.

3. useradd - это команда для создания нового пользователя. Здесь:
   - --home-dir /home/g10 - устанавливает домашнюю директорию пользователя как /home/g10.
   - --create-home - создаёт домашнюю директорию пользователя, если она не существует.
   - --uid 1000 - устанавливает идентификатор пользователя как 1000.
   - --gid 1000 - устанавливает идентификатор группы пользователя как 1000.
   - --shell /bin/bash - указывает исполняемый оболочку пользователя как /bin/bash.
   - --skel /dev/null - отключает использование шаблонной структуры домашней директории пользователя.

Таким образом, данная запись в Dockerfile создаёт группу с именем g10 и идентификатором 1000, а затем создаёт пользователя с именем g10, домашней директорией /home/g10, идентификатором 1000, принадлежащего к созданной группе и использующего оболочку /bin/bash

